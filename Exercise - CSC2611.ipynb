{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\anna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(brown.words())\n",
    "pdist = nltk.MLEProbDist(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [w[0] for w in fdist.most_common(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', ',', '.', 'of', 'and']\n",
      "['expanded', 'emphasize', 'Manhattan', 'temporarily', 'puts']\n"
     ]
    }
   ],
   "source": [
    "print(W[:5])\n",
    "print(W[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = [\"asylum\", \"autograph\", \"boy\", \"brother\", \"car\", \"coast\", \"cock\", \n",
    " \"cord\", \"crane\", \"cushion\", \"food\", \"furnace\", \"gem\", \"glass\", \n",
    " \"graveyard\", \"grin\", \"mound\", \"noon\", \"oracle\", \"slave\", \"tool\", \n",
    " \"voyage\", \"wizard\", \"woodland\", \"automobile\", \"bird\", \"cemetery\",\n",
    " \"forest\", \"fruit\", \"hill\", \"implement\", \"jewel\", \"journey\", \"had\",\n",
    " \"madhouse\", \"magician\", \"midday\", \"monk\", \"pillow\", \"rooster\", \n",
    " \"sage\", \"serf\", \"shore\", \"signature\", \"smile\", \"stove\", \"string\",\n",
    " \"tumbler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5030\n"
     ]
    }
   ],
   "source": [
    "for w in new_words:\n",
    "    if w not in W:\n",
    "        W.append(w)\n",
    "print(len(W))\n",
    "W = np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_bigrams = nltk.ConditionalFreqDist(nltk.bigrams(brown.words()))\n",
    "pd_bigrams = nltk.ConditionalProbDist(fd_bigrams, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "1.5380002673367443e-08\n"
     ]
    }
   ],
   "source": [
    "print(fd_bigrams['the']['dog'])\n",
    "print(pd_bigrams['the'].prob('dog')*pdist.prob('dog'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_dense = np.zeros((len(W), len(W)))\n",
    "for i, w1 in enumerate(W):\n",
    "    for j, w2 in enumerate(W):\n",
    "        M1_dense[i][j] = pd_bigrams[w1].prob(w2)*pdist.prob(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_counts = np.zeros((len(W), len(W)))\n",
    "for i, w1 in enumerate(W):\n",
    "    for j, w2 in enumerate(W):\n",
    "        M1_counts[i][j] = fd_bigrams[w1][w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = csr_matrix(M1_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.zeros((len(W), len(W)))\n",
    "for i, w1 in enumerate(W):\n",
    "    for j, w2 in enumerate(W):\n",
    "        probs[i][j] = pdist.prob(w1) * pdist.prob(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_plus_dense = np.zeros((len(W), len(W)))\n",
    "div = np.divide(M1_dense, probs, where=(probs!=0))\n",
    "M1_plus_dense = np.log2(div, where=(div!=0))\n",
    "for i, _ in enumerate(M1_plus_dense):\n",
    "    for j, _ in enumerate(M1_plus_dense[i]):\n",
    "        M1_plus_dense[i][j] = max(0, M1_plus_dense[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1_plus = csr_matrix(M1_plus_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd10 = PCA(n_components=10)\n",
    "M2_10 = svd10.fit_transform(M1_plus_dense)\n",
    "svd100 = PCA(n_components=100)\n",
    "M2_100 = svd100.fit_transform(M1_plus_dense)\n",
    "svd300 = PCA(n_components=300)\n",
    "M2_300 = svd300.fit_transform(M1_plus_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 61\n"
     ]
    }
   ],
   "source": [
    "P = [(\"cord\", \"smile\"), (\"rooster\", \"voyage\"), (\"noon\", \"string\"), \n",
    "     (\"fruit\", \"furnace\"), (\"autograph\", \"shore\"), (\"automobile\", \"wizard\"),\n",
    "     (\"mound\", \"stove\"), (\"grin\", \"implement\"), (\"asylum\", \"fruit\"),\n",
    "     (\"asylum\", \"monk\"), (\"graveyard\", \"madhouse\"), (\"glass\", \"magician\"),\n",
    "     (\"boy\", \"rooster\"), (\"cushion\", \"jewel\"), (\"monk\", \"slave\"),\n",
    "     (\"asylum\", \"cemetery\"), (\"coast\", \"forest\"),\n",
    "     (\"shore\", \"woodland\"), (\"monk\", \"oracle\"), (\"boy\", \"sage\"),\n",
    "     (\"automobile\", \"cushion\"), (\"mound\", \"shore\"),\n",
    "     (\"forest\", \"graveyard\"), (\"food\", \"rooster\"), (\"cemetery\", \"woodland\"),\n",
    "     (\"shore\", \"voyage\"), (\"bird\", \"woodland\"), (\"coast\", \"hill\"),\n",
    "     (\"furnace\", \"implement\"), (\"crane\", \"rooster\"), (\"hill\", \"woodland\"),\n",
    "     (\"car\", \"journey\"), (\"cemetery\", \"mound\"), (\"glass\", \"jewel\"),\n",
    "     (\"magician\", \"oracle\"), (\"crane\", \"implement\"),\n",
    "     (\"sage\", \"wizard\"), (\"oracle\", \"sage\"), (\"bird\", \"crane\"),\n",
    "     (\"bird\", \"cock\"), (\"food\", \"fruit\"), (\"brother\", \"monk\"), \n",
    "     (\"asylum\", \"madhouse\"), (\"furnace\", \"stove\"),\n",
    "     (\"magician\", \"wizard\"), (\"hill\", \"mound\"), (\"cord\", \"string\"),\n",
    "     (\"glass\", \"tumbler\"), (\"grin\", \"smile\"), (\"serf\", \"slave\"),\n",
    "     (\"journey\", \"voyage\"), (\"autograph\", \"signature\"), (\"coast\", \"shore\"),\n",
    "     (\"forest\", \"woodland\"), (\"implement\", \"tool\"), (\"cock\", \"rooster\"),\n",
    "     (\"cushion\", \"pillow\"), (\"cemetery\", \"graveyard\"),\n",
    "     (\"automobile\", \"car\"), (\"midday\", \"noon\"), (\"gem\", \"jewel\")]\n",
    "S = [0.02, 0.04, 0.04, 0.05, 0.06, 0.11, 0.14, 0.18, 0.19, 0.39, 0.42,\n",
    "    0.44, 0.44, 0.45, 0.57, 0.79, 0.85, 0.90, 0.91, 0.96, 0.97,\n",
    "    0.97, 1.00, 1.09, 1.18, 1.22, 1.24, 1.26, 1.37, 1.41, 1.48,\n",
    "    1.55, 1.69, 1.78, 1.82, 2.37, 2.46, 2.61, 2.63, 2.63, 2.69,\n",
    "    2.74, 3.04, 3.11, 3.21, 3.29, 3.41, 3.45, 3.46, 3.46, 3.58, 3.59, \n",
    "    3.60, 3.65, 3.66, 3.68, 3.84, 3.88, 3.92, 3.94, 3.94]\n",
    "print(len(P), len(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype='<U10')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_M1 = [float(cosine_similarity(M1[np.where(W == w1)[0]], M1[np.where(W == w2)[0]])[0]) for (w1, w2) in P]\n",
    "S_M1_plus = [float(cosine_similarity(M1_plus[np.where(W == w1)[0]], M1_plus[np.where(W == w2)[0]])[0]) for (w1, w2) in P]\n",
    "S_M2_10 = [float(cosine_similarity(M2_10[np.where(W == w1)[0]], M2_10[np.where(W == w2)[0]])[0]) for (w1, w2) in P]\n",
    "S_M2_100 = [float(cosine_similarity(M2_100[np.where(W == w1)[0]], M2_100[np.where(W == w2)[0]])[0]) for (w1, w2) in P]\n",
    "S_M2_300 = np.array([float(cosine_similarity(M2_300[np.where(W == w1)[0]], M2_300[np.where(W == w2)[0]])[0]) for (w1, w2) in P])\n",
    "\n",
    "# print(np.where(S_M2_300 >= 0.9))\n",
    "np.array(P)[np.where(S_M2_300 >= 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.14720707674998043, 0.2575842256998856)\n",
      "(0.20666776280348725, 0.11003426959226345)\n",
      "(0.20851598019109546, 0.10682021057203918)\n",
      "(0.28473404526172186, 0.0261420090815637)\n",
      "(0.31016088046240925, 0.014989193551728036)\n"
     ]
    }
   ],
   "source": [
    "print(pearsonr(S, S_M1))\n",
    "print(pearsonr(S, S_M1_plus))\n",
    "print(pearsonr(S, S_M2_10))\n",
    "print(pearsonr(S, S_M2_100))\n",
    "print(pearsonr(S, S_M2_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exercise_M2_300.pkl\", \"wb\") as file:\n",
    "    pickle.dump(M2_300, file)\n",
    "with open(\"exercise_W.pkl\", \"wb\") as file:\n",
    "    pickle.dump(W, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "words = W\n",
    "vectors = M2_300\n",
    "model = KeyedVectors(vectors.shape[1])\n",
    "model.add(words, vectors)\n",
    "model.save('m2_300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
